{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ff05887",
   "metadata": {},
   "source": [
    "In this section templates will be developed for XGBoost models. Later on, these templates can be referenced as starting points for building XGBoost classifiers and regressors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6011616a",
   "metadata": {},
   "source": [
    "## XGBoost - Classification Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30c691b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f5ff7e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fd055fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (150, 4)\n",
      "Feature names: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "Target names: ['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "# Scikit-Learn datasets are stored as NumPy arrays\n",
    "print(f\"Dataset shape: {iris.data.shape}\")\n",
    "print(f\"Feature names: {iris.feature_names}\")\n",
    "print(f\"Target names: {iris.target_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df4a9b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(\n",
    "    data=np.c_[iris.data, iris.target],\n",
    "    columns= iris.feature_names + ['target']\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a30080d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.iloc[:, :-1], df.iloc[:, -1],\n",
    "    random_state= 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a89806f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "xgb_cls = XGBClassifier(\n",
    "    booster='gbtree', objective='multi:softprob', \n",
    "    max_depth=6, learning_rate=0.1, n_estimators=100, \n",
    "    random_state=2, n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bdf308",
   "metadata": {},
   "source": [
    "- `booster:'gbtree'`: The booster is the base learner. It is machine learning model that is constructed during every round of boosting. *gbtree* stands for gradient boosted tree.\n",
    "\n",
    "- `objective='multi:softprob'`: This objective is a standard alternative to *binary:logistic* when the dataset includes **multiple classes**. If not explicitly stated, XGBoost will often find the right objective for you.\n",
    "\n",
    "- `'max_depth=6'`: Determines the number of branches each tree has. XGBoost uses a default 6.\n",
    "\n",
    "- `'learning_rate=0.1'`: Within XGBoost, this hyperparameter is often referred as **eta**. Limits the variance by reducing the weight of each tree to the given percentage.\n",
    "\n",
    "- `'n_estimators=100'`: Number of boosted trees in the model. Increasing this number while decreasing *learning_rate* can lead to more robust results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e5db7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:31:15] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Score: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "xgb_cls.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgb_cls.predict(X_test)\n",
    "\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print(f\"Score: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4d2082",
   "metadata": {},
   "source": [
    "An initial score of **97.4** percent on the Iris Dataset using default hyperparameters is very good."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7910ead",
   "metadata": {},
   "source": [
    "## XGBoost - Regression Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b265d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442, 10)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = datasets.load_diabetes(return_X_y=True)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "433aadcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_reg = XGBRegressor(\n",
    "    booster='gbtree', objective='reg:squarederror', \n",
    "    max_depth=6, learning_rate=0.1, n_estimators=100,\n",
    "    random_state=2, n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9cb082cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: [63.033 59.689 64.538 63.699 64.661]\n",
      "RMSE mean: 63.124\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(xgb_reg, X, y, scoring=\"neg_mean_squared_error\", cv=5)\n",
    "\n",
    "rmse = np.sqrt(-scores)\n",
    "print(f\"RMSE: {np.round(rmse, 3)}\")\n",
    "print(f\"RMSE mean: {np.round(rmse.mean(), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b78ce4",
   "metadata": {},
   "source": [
    "Without a baseline of comparison, we have no idea what that score means. Converting the target column, y, into a pandas DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea17697b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>442.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>152.133484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>77.093005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>87.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>140.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>211.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>346.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "count  442.000000\n",
       "mean   152.133484\n",
       "std     77.093005\n",
       "min     25.000000\n",
       "25%     87.000000\n",
       "50%    140.500000\n",
       "75%    211.500000\n",
       "max    346.000000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3ed81d",
   "metadata": {},
   "source": [
    "A score of **63.124** is less than 1 standard deviation, a respectable result."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
